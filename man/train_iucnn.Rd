% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_iucnn.R
\name{train_iucnn}
\alias{train_iucnn}
\title{Train an IUCNN Model}
\usage{
train_iucnn(
  x,
  lab,
  mode = "nn-class",
  path_to_output = ".",
  model_name = "iuc_nn_model",
  validation_split = 0.1,
  test_fraction = 0.1,
  cv_fold = 1,
  seed = 1234,
  max_epochs = 1000,
  n_layers = "60_60_20",
  use_bias = TRUE,
  act_f = "relu",
  act_f_out = "auto",
  label_stretch_factor = 1,
  patience = 200,
  randomize_instances = TRUE,
  dropout_rate = 0,
  mc_dropout = TRUE,
  mc_dropout_reps = 100,
  label_noise_factor = 0,
  rescale_features = FALSE,
  save_model = TRUE,
  overwrite = FALSE,
  verbose = 1
)
}
\arguments{
\item{x}{a data.set, containing a column "species"
with the species names, and
subsequent columns with different features, in the
same order as used for \code{\link{predict_iucnn}}.}

\item{lab}{an object of the class iucnn_labels, as generated by
\code{\link{prep_labels}} containing the labels for all species.}

\item{mode}{character string. Choose between the IUCNN models
"nn-class" (default, tensorflow neural network classifier),
"nn-reg" (tensorflow neural network regression), or "bnn-class" (Bayesian neural network classifier)}

\item{path_to_output}{character string. The path to the location
where the IUCNN model shall be saved}

\item{model_name}{character string. The name used to save the trained model.}

\item{validation_split}{numeric. The fraction of the input data used as validation set.}

\item{test_fraction}{numeric. The fraction of the input data used as test set.}

\item{seed}{reset the python random seed.}

\item{max_epochs}{integer. The maximum number of epochs.}

\item{n_layers}{numeric vector with length of at least one.
The vector quantifies the number of nodes
used in each hidden layer of the neural network.
This also implicitly specifies the number of hidden
layers. For example, n_layers = c(60, 10) defines a model
with two hidden layers with 60 and 10 nodes
respectively. Note that the number of nodes in the output
layer is automatically determined based on
the number of unique labels in the training set.}

\item{use_bias}{logical. Specifies if a bias node is used in the first hidden layer (default=TRUE).}

\item{act_f}{character string. Specifies the activation function should be used in the hidden layers.
Available options are: "relu" (default), "tanh", "sigmoid"}

\item{act_f_out}{character string. Similar to act_f, this specifies
the activation function for the output
layer. When setting to "auto" (default), a suitable output activation
function will be chosen based on the
chosen mode. Other valid options are "softmax" (nn-class, bnn-class), "tanh" (nn-reg),
"sigmoid" (nn-reg), or no activation function "" (nn-reg)}

\item{label_stretch_factor}{numeric. When choosing mode "nn-reg" the
labels will be rescaled and this rescaling can be
further adjusted by this factor. A factor smaller than 1.0 will
compress the range of possible labels.}

\item{patience}{integer. Number of epochs with no improvement
after which training will be stopped.}

\item{randomize_instances}{logical. When set to TRUE (default) the
instances will be shuffled before training (recommended).}

\item{dropout_rate}{numeric. Apply Monte Carlo dropout to the NN model.
This will randomly turn off the specified fraction of
nodes of the neural network during each epoch of training
as well as during prediction, making the NN more stable and
less reliant on individual nodes/weights
(only available for modes nn-class and nn-reg).}

\item{label_noise_factor}{numeric. Add random noise to the input labels after
rescaling to give the categorical labels a more
continuous spread before training the regression model (only available for mode nn-reg).}

\item{rescale_features}{logical. Set to TRUE if all feature
values shall be rescaled
to values between 0 and 1 prior to training (default=FALSE).}

\item{overwrite}{logical. If TRUE existing models are overwritten. Default is to FALSE,}
}
\value{
a folder in the working directory (or as specified with path_to_output)
with the trained model,
for use by \code{\link{predict_iucnn}}.
}
\description{
Trains an IUCNN model based on a data,frame of features,
for instance generated by \code{\link{ft_geo}}, \code{\link{ft_clim}},
and \code{\link{ft_biom}},
and a dataset of labels, (i.e. IUCNN classes) for each species. Note
that NAs are not allowed in the features, and taxa with NAs will
automatically be removed! Also taxa missing in either the labels
or features will be removed.
}
\note{
See \code{vignette("Approximate_IUCN_Red_List_assessments_with_IUCNN")} for a
tutorial on how to run IUCNN.o
}
\examples{
\dontrun{
data("training_occ") #geographic occurrences of species with IUCN assessment
data("training_labels")# the corresponding IUCN assessments
data("prediction_occ") #occurrences from Not Evaluated species to prdict

# 1. Feature and label preparation
features <- prep_features(training_occ) # Training features
labels_train <- prep_labels(training_labels) # Training labels
features_predict <- prep_features(prediction_occ) # Prediction features

# 2. Model training
m1 <- train_iucnn(x = features, lab = labels_train)

summary(m1)
plot(m1)
}


}
\keyword{Prediction}
