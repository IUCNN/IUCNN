% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/modeltest_iucnn.R
\name{modeltest_iucnn}
\alias{modeltest_iucnn}
\title{Train a set of IUCNN models and log results to pick best model configuration}
\usage{
modeltest_iucnn(
  x,
  lab,
  logfile = "model_testing_logfile.txt",
  model_outpath = "modeltest",
  mode = "nn-class",
  cv_fold = 5,
  validation_fraction = 0,
  n_layers = c("50_30_10", "30"),
  dropout_rate = c(0, 0.1, 0.3),
  use_bias = TRUE,
  balance_classes = FALSE,
  seed = 1234,
  label_stretch_factor = 1,
  label_noise_factor = 0,
  act_f = "relu",
  act_f_out = "auto",
  max_epochs = 5000,
  patience = 200,
  mc_dropout = TRUE,
  mc_dropout_reps = 100,
  randomize_instances = TRUE,
  rescale_features = FALSE,
  init_logfile = TRUE,
  recycle_settings = FALSE
)
}
\arguments{
\item{x}{a data.frame of model-testing results as produced
by \code{\link{modeltest_iucnn}}}

\item{criterion}{name the criterion to rank models by (default="val_acc"). Valid options are
"val_acc","val_loss","weighted_error", or "total_class_matches"
(see details below):
\itemize{
\item val_acc: highest validation accuracy
\item val_loss: lowest validation loss
\item weighted_error: lowest weighted error, e.g. an LC species misclassified as
CR has a weighted error of 4-0 = 4, while an LC species
misclassified as NT has a weighted error of 1-0 = 1.
These error scores are summed across all validation
predictions
\item total_class_matches: picks the model that best reproduces the class
distribution in the validation data. When picking
this criterion it is not considered whether or not
individual instances are predicted correctly, but
instead it only looks at the overall class distribution
in the predicted data
}}

\item{require_dropout}{logical (default=FALSE). If set to TRUE, the best model
that contains a dropout rate of > 0 will be picked, even if other non-dropout
models scored higher given the chosen criterion. Dropout models are required
for certain functionalities within IUCNN, such as e.g. choosing a target
accuracy when using predict_iucnn.}
}
\value{
outputs an \code{iucnn_model} object containing all information about the best model.
}
\description{
Uses a data-frame of model-testing results generated with
\code{\link{modeltest_iucnn}} as input, and finds the best model
based on the chosen criterion.
}
\note{
See \code{vignette("Approximate_IUCN_Red_List_assessments_with_IUCNN")} for a
tutorial on how to run IUCNN.
}
\examples{
\dontrun{
# Model-testing
logfile = paste0("model_testing_results.txt")
model_testing_results = modeltest_iucnn( features,
                                        labels,
                                        logfile,
                                        model_outpath = 'iucnn_modeltest',
                                        mode = 'nn-class',
                                        seed = 1234,
                                        dropout_rate = c(0.0,0.1,0.3),
                                        n_layers = c('30','40_20','50_30_10'),
                                        cv_fold = 5,
                                        init_logfile = TRUE)

# Selecting best model based on chosen criterion
best_iucnn_model = bestmodel_iucnn(model_testing_results,
                                   criterion = 'val_acc',
                                   require_dropout = TRUE)
}


}
