#' Train an IUCNN Model
#'
#'Trains an IUCNN model based on a data,frame of features,
#'for instance generated by \code{\link{ft_geo}}, \code{\link{ft_clim}}, and \code{\link{ft_biom}},
#'and a dataset of labels, (i.e. IUCNN classes) for each species.
#'
#'
#'
#'@param x a data.set, containing a column "species" with the species names, and
#'subsequent columns with different features, in the same order as used for \code{\link{predict_iucnn}}.
#'@param lab an object of the class iucnn_labels, as generated by
#' \code{\link{prep_labels}} containing the labels for all species.
#'@param path_to_output character string. The path to the location
#'where the IUCNN model shall be saved
#'@param model_name character string. The name used to save the trained model.
#'@param validation_split numeric. The fraction of the input data used as validation set.
#'@param test_fraction numeric. The fraction of the input data used as test set.
#'@param seed reset the python random seed.
#'@param max_epochs integer. The maximum number of epochs.
#'@param n_layers numeric vector with length of at least one. The vector quantifies the number of nodes
#'used in each hidden layer of the neural network. This also implicitly specifies the number of hidden
#'layers. For example, n_layers = c(60, 10) defines a model with two hidden layers with 60 and 10 nodes
#' respectively. Note that the number of nodes in the output layer is automatically determined based on
#'the number of unique labels in the training set.
#'@param use_bias integer (1/0). Specifies if a bias node is used in the first hidden layer.
#'@param act_f character string. Specifies the activation function should be used in the hidden layers.
#'Available options are: "relu" (default), "tanh", "sigmoid"
#'@param patience integer. Number of epochs with no improvement after which training will be stopped.
#'
#'
#'@note See \code{vignette("Approximate_IUCN_Red_List_assessments_with_IUCNN")} for a
#'tutorial on how to run IUCNN.
#'
#'@return a folder in the working directory (or as specified with path_to_output) with the trained model,
#'for use by \code{\link{predict_iucnn}}.
#'
#' @keywords Prediction

#' @examples
#'\dontrun{
#'dat <- data.frame(species = c("A", "B")
#'                 decimallongitude = runif (200,-5,5),
#'                 decimallatitude = runif (200,-5,5))
#'labels <- c(1,0)
#'
#'train_feat <- geo_features(dat)
#'
#'not_eval <- data.frame(species = c(A", "B")
#'                 decimallongitude = runif (200,-5,5),
#'                 decimallatitude = runif (200,-5,5))
#'
#'predict_feat <- geo_features(not_eval)
#'
#'train_iucnn(x = train_feat,
#'            label = labels)
#'
#'
#'predict_iucnn(x = predict_feat,
#'              model_dir = iuc_nn_model")
#'}
#'
#'
#' @export
#' @importFrom reticulate source_python
#' @importFrom utils read.table
#' @importFrom magrittr %>%
#' @importFrom dplyr select left_join mutate
#' @importFrom stats complete.cases
#' @importFrom checkmate assert_data_frame assert_character assert_logical assert_numeric

train_iucnn <- function(x,
                        lab,
                        path_to_output=".",
                        model_name = "iuc_nn_model",
                        validation_split = 0.1,
                        test_fraction = 0.1,
                        seed = 1234,
                        max_epochs = 1000,
                        n_layers = c(60,60,20),
                        use_bias = TRUE,
                        act_f = "relu",
                        act_f_out = "auto",
                        label_stretch_factor = 1.0,
                        patience = 200,
                        randomize_instances = TRUE,
                        mode='nn-class',
                        rescale_features = FALSE,
                        return_categorical = FALSE){

  # Check input
  ## assertion
  assert_data_frame(x)
  assert_class(lab, classes = "iucnn_labels")
  assert_character(path_to_output)
  assert_numeric(validation_split, lower = 0, upper = 1)
  assert_numeric(test_fraction, lower = 0, upper = 1)
  assert_numeric(seed)
  assert_numeric(max_epochs)
  assert_numeric(n_layers)
  assert_logical(use_bias)
  assert_character(act_f)
  assert_character(act_f_out)
  assert_numeric(label_stretch_factor, lower = 0, upper = 1)
  assert_numeric(patience)
  assert_logical(randomize_instances)
  assert_character(mode)
  assert_logical(rescale_features)
  assert_logical(return_categorical)

  ## specific checks
  if(!"species" %in% names(x)){
    stop("species column not found in x.
         The features input need a column named 'species'
         with the species names matching those in labels")
  }

  match.arg(mode, choices = c("nn-class", "nn-reg", "bnn-class"))

  # merge species and labels to match order
  tmp.in <- left_join(x, lab$labels, by = "species")

  if(nrow(tmp.in) != nrow(x)){
    mis <- x$species[!x$species %in% tmp$species]
    warning("Labels for species not found, species removed.\n", paste(mis, "\n"))
  }

  if(nrow(tmp.in) != nrow(lab$labels)){
    mis <- lab$labels$species[!lab$labels$species %in% tmp$species]
    warning("Labels for species not found, species removed.\n", paste(mis, "\n"))
  }

  # complete cases only
  tmp <- tmp.in[complete.cases(tmp.in),]

  if(nrow(tmp) != nrow(tmp.in)){
    mis <- tmp.in[!complete.cases(tmp.in),]
    warning("Information for species was incomplete, species removed\n", paste(mis$species, "\n"))
  }

  # prepare input data for the python function
  dataset <- tmp %>%
    dplyr::select(-.data$species, -.data$labels)

  dataset_bnn <- tmp[,1:length(names(tmp))-1]

  instance_names <- tmp %>%
    dplyr::select(.data$species)

  labels <- tmp %>%
    dplyr::select(.data$labels)

  # prepare labels to start at 0
  if(min(labels$labels) != 0){
    warning(sprintf("Labels need to start at 0. Labels substracted with %s", min(labels$labels)))

    labels <-  labels %>%
      dplyr::mutate(labels = .data$labels - min(.data$labels))
  }
  # set out act fun if chosen auto
  if (act_f_out == 'auto'){
    if (mode == 'nn-reg'){
      act_f_out = 'tanh'
    }else if(mode == 'bnn-class'){
      act_f_out = 'swish'
    }else{
      act_f_out = 'softmax'
    }
  }

  if (mode=='bnn-class'){
    # in the current npbnn function we need to add a dummy column of instance names
    labels[['names']] = replicate(length(labels$labels),'sp.')
    labels = labels[,c('names','labels')]
    # transform the data into BNN compatible format
    bnn_data = bnn_load_data(dataset_bnn,
                             labels,
                             seed=as.integer(seed),
                             testsize=test_fraction,
                             all_class_in_testset=FALSE,
                             header=TRUE, # input data has a header
                             instance_id=TRUE, # input data includes names of instances
                             from_file=FALSE
    )

    # define number of layers and nodes per layer for BNN
    # define the BNN model
    bnn_model = create_BNN_model(bnn_data,
                                 n_layers,
                                 actfun = act_f_out,
                                 seed=1234
    )

    # set up the MCMC environment
    update_frequencies = rep(0.05,length(n_layers)+1)
    update_window_sizes = rep(0.075,length(n_layers)+1)
    mcmc_object = MCMC_setup(bnn_model,
                             update_frequencies,
                             update_window_sizes,
                             n_iteration = as.integer(max_epochs),
                             sampling_f = 10
    )

    # run the MCMC and write output to file
    logger = run_MCMC(bnn_model,
                      mcmc_object,
                      filename_stem = paste0(path_to_output,'/','BNN')
    )

    # calculate test accuracy
    post_pr_test = calculate_accuracy(bnn_data,
                                           logger,
                                           bnn_model,
                                           post_summary_mode=0
    )

    input_data = bnn_data

    logfile_path = as.character(py_get_attr(logger,'_logfile'))
    log_file_content = read.table(logfile_path,sep = '\t',header = TRUE)
    pklfile_path = as.character(py_get_attr(logger,'_pklfile'))

    test_labels = bnn_data$test_labels
    test_predictions = apply(post_pr_test$post_prob_predictions,1,which.max)-1
    test_predictions_raw = post_pr_test$post_prob_predictions

    confusion_matrix = post_pr_test$confusion_matrix
    confusion_matrix = confusion_matrix[1:dim(confusion_matrix)[1]-1,1:dim(confusion_matrix)[2]-1] #remove the sum row and column

    training_accuracy = log_file_content$accuracy[length(log_file_content$accuracy)]
    validation_accuracy = NaN
    test_accuracy = post_pr_test$mean_accuracy

    training_loss = (-log_file_content$likelihood[length(log_file_content$likelihood)])/length(bnn_data$labels)
    validation_loss = NaN
    test_loss = NaN

    training_loss_history = (-log_file_content$likelihood)/length(bnn_data$labels)
    validation_loss_history = NaN

    training_accuracy_history = log_file_content$accuracy
    validation_accuracy_history = NaN

    training_mae_history = NaN
    validation_mae_history = NaN

    rescale_labels_boolean = FALSE
    label_rescaling_factor = as.integer(max(labels$labels))
    min_max_label = as.vector(c(min(labels$labels),max(labels$labels)))
    label_stretch_factor = label_stretch_factor

    activation_function = act_f_out
    trained_model_path = pklfile_path

  }else{

    # source python function
    reticulate::source_python(system.file("python", "IUCNN_train.py", package = "IUCNN"))

    #write.table(as.matrix(dataset),'manual_tests/features_tutorial_data.txt',sep='\t',quote=FALSE,row.names=FALSE)
    #write.table(as.matrix(labels),'manual_tests/labels_tutorial_data.txt',sep='\t',quote=FALSE,row.names=FALSE)
    #write.table(as.matrix(instance_names),'manual_tests/instance_names_tutorial_data.txt',sep='\t',quote=FALSE,row.names=FALSE)
    #write.table(names(dataset),'manual_tests/feature_names_tutorial_data.txt',sep='\t',quote=FALSE,row.names=FALSE)

    # run model via python script
    res = iucnn_train(dataset = as.matrix(dataset),
                      labels = as.matrix(labels),
                      mode = mode,
                      path_to_output = path_to_output,
                      model_name = model_name,
                      validation_split = validation_split,
                      test_fraction = test_fraction,
                      seed = as.integer(seed),
                      instance_names = as.matrix(instance_names),
                      feature_names = names(dataset),
                      verbose = 0,
                      max_epochs = as.integer(max_epochs),
                      n_layers = as.list(n_layers),
                      use_bias = use_bias,
                      act_f = act_f,
                      act_f_out = act_f_out,
                      stretch_factor_rescaled_labels = label_stretch_factor,
                      patience = patience,
                      randomize_instances = as.integer(randomize_instances),
                      rescale_features = rescale_features
    )

    test_labels = as.vector(res[[1]])
    test_predictions = as.vector(res[[2]])
    test_predictions_raw = res[[3]]

    training_accuracy = res[[4]]
    validation_accuracy = res[[5]]
    test_accuracy = res[[6]]

    training_loss = res[[7]]
    validation_loss = res[[8]]
    test_loss = res[[9]]

    training_loss_history = as.vector(res[[10]])
    validation_loss_history = as.vector(res[[11]])

    training_accuracy_history = as.vector(res[[12]])
    validation_accuracy_history = as.vector(res[[13]])

    training_mae_history = as.vector(res[[14]])
    validation_mae_history = as.vector(res[[15]])

    rescale_labels_boolean = res[[16]]
    label_rescaling_factor = res[[17]]
    min_max_label = as.vector(res[[18]])
    label_stretch_factor = res[[19]]

    activation_function = res[[20]]
    trained_model_path = res[[21]]

    confusion_matrix = res[[22]]

    input_data = res[[23]]
    }

  named_res <- NULL

  named_res$input_data = c(input_data, lookup = data.frame(lab$lookup))

  named_res$rescale_labels_boolean <- rescale_labels_boolean
  named_res$label_rescaling_factor <- label_rescaling_factor
  named_res$min_max_label_rescaled <- min_max_label
  named_res$label_stretch_factor <- label_stretch_factor

  named_res$activation_function <- activation_function
  named_res$trained_model_path <- trained_model_path

  named_res$model <- mode

  named_res$training_loss_history <- training_loss_history
  named_res$validation_loss_history <- validation_loss_history

  named_res$training_accuracy_history <- training_accuracy_history
  named_res$validation_accuracy_history <- validation_accuracy_history

  named_res$training_mae_history <- training_mae_history
  named_res$validation_mae_history <- validation_mae_history

  named_res$training_loss <- training_loss
  named_res$validation_loss <- validation_loss
  named_res$test_loss  <- test_loss

  named_res$test_predictions_raw <- test_predictions_raw #softmax probs, posterior probs, or regressed values
  named_res$test_predictions <- test_predictions
  named_res$test_labels <- test_labels

  named_res$confusion_matrix = confusion_matrix

  named_res$training_accuracy <- training_accuracy
  named_res$validation_accuracy <- validation_accuracy
  named_res$test_accuracy <- test_accuracy

  class(named_res) <- "iucnn_model"

  return(named_res)
}
